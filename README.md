# Ridge Regression From Scratch (m & b)

-> This project implements **Ridge Regression (L2 Regularization)** fully from scratch by calculating and updating the parameters **m (slope)** and **b (intercept)** manually using           Gradient Descent.  
-> It helps you understand how the regularization term modifies the optimization process and stabilizes the model.


## **What This Project Covers**
### Derivation of Ridge Loss Function  
Includes L2 penalty term:  
\[
Loss = MSE + \lambda (m^2)
\]

### Gradient Descent Update Rules  
Manually derived updates for:
-> Slope **m**
-> Intercept **b**
-> Regularization effect on gradient

### Ridge vs Simple Linear Regression  
Shows how values change with/without regularization.

### Visualization:
Plots:
-> Data points  
-> Prediction line  
-> Loss curve  


## **Key Learning Outcomes**
-> Understand how L2 regularization works  
-> Know how m & b are optimized with penalty  
-> Learn to prevent overfitting using Ridge Regression  
-> Build full model from pure Python & NumPy  


## **Technologies Used**
-> Python  
-> NumPy  
-> Matplotlib  


